version: 2.1
# Destroying CloudFormation Stacks Environment
commands:
  destroy:
    description: Destroy all CloudFormation stacks with a given workflow ID.
    steps:
      - run:
          name: Delete all files from the S3 bucket created
          command: |
            if aws s3api head-bucket --bucket udapeople-hieunt114
            then
              aws s3 rm s3://udapeople-hieunt114/ --recursive
            fi
          when: on_fail
      - run:
          name: Delete the AWS CloudFormation stacks
          command: |
            if aws cloudformation wait stack-exists --stack-name Udapeople-hieunt114
            then 
              aws cloudformation delete-stack --stack-name Udapeople-hieunt114
            fi
            if aws cloudformation wait stack-exists --stack-name UdapeopleB
            then
              aws cloudformation delete-stack --stack-name UdapeopleB
            fi
          when: on_fail

  revert-migration:
    description: Revert the latest migration
    steps:
      - run:
          name: Get the public DNS of EC2 instance from https://memstash.io/
          command: |
            PUBLIC_DNS=$(curl -H "token: hieunt114" --request GET https://api.memstash.io/values/public_dns)
            echo ${PUBLIC_DNS}
            cd .circleci/ansible/
            echo "[all]" > ./inventory
            echo ${PUBLIC_DNS} >> ./inventory
            cat ./inventory
          when: on_fail
      - add_ssh_keys:
          fingerprints: ["33:c8:64:fb:aa:80:1b:63:c6:98:30:9a:c8:8c:9a:14"]
      - run:
          name: Revert the last migration
          command: |
            printenv >> ./backend/.env
            cd .circleci/ansible/
            ansible-playbook -i ./inventory db_rollback.yml
          when: on_fail

jobs:
  build-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build-v1]
      - run:
          name: Build front-end
          command: |
            cd frontend
            npm i
            npm run build
            npm audit fix --audit-level=critical --force
      - save_cache:
          paths: [frontend/node_modules]
          key: frontend-build-v1

  build-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build-v1]
      - run:
          name: Back-end build
          command: |
            cd backend
            npm i
            npm run build
            npm audit fix --audit-level=critical --force
      - save_cache:
          paths: [backend/node_modules]
          key: backend-build-v1

  test-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build-v1]
      - run:
          name: front-end test
          command: |

            cd frontend
            npm i
            npm run test
            npm audit fix --audit-level=critical --force

  test-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build-v1]
      - run:
          name: Back-end build
          command: |
            echo 'Testing backend'
            cd backend
            npm install
            npm run test
            npm audit fix --audit-level=critical --force

  scan-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build-v1]
      - run:
          name: front-end scan
          command: |
            echo 'Scanning Frontend'
            cd frontend
            npm i
            npm audit fix --audit-level=critical --force

  scan-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build-v1]
      - run:
          name: Back-end scan
          command: |
            echo 'Scanning Backend'
            cd backend
            npm audit fix --audit-level=critical --force

  deploy-infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Ensure back-end infrastructure exists
          command: |
            echo 'Deploying backend stack'
            aws cloudformation deploy \
              --template-file .circleci/files/backend.yml \
              --tags project=Udapeople_B \
              --stack-name "UdapeopleB" \
              --parameter-overrides ID="hieunt114"
      - run:
          name: Get and save public DNS of EC2 instance to https://memstash.io/
          command: |
            echo 'Getting and Saving public DNS'
            PUBLIC_DNS=$(aws ec2 describe-instances --region us-east-1 --filters 'Name=tag:Name,Values=backend-hieunt114' --query "Reservations[*].Instances[0].PublicDnsName" --output text)
            echo ${PUBLIC_DNS}
            curl -H "Content-Type: text/plain" \
               -H "token: hieunt114" \
               --request PUT \
               --data ${PUBLIC_DNS} \
               https://api.memstash.io/values/public_dns
      - run:
          name: Ensure front-end infrastructure exist
          command: |
            echo 'Ensuring front-end infrastructure exist'
            aws cloudformation deploy \
              --template-file .circleci/files/frontend.yml \
              --tags project=Udapeople_F \
              --stack-name "Udapeople-hieunt114" \
              --parameter-overrides ID="hieunt114"
      - destroy

  deploy-backend:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            echo 'Installing aws cli'
            apk add --no-cache curl
            apk add --no-cache --upgrade bash
            apk add --no-cache --update ansible
            apk add --no-cache openssh-client
            pip3 install awscli
      - run:
          name: Get the public DNS of EC2 instance from https://memstash.io/
          command: |
            echo 'Getting the public DNS of EC2 Instance from link'
            PUBLIC_DNS=$(curl -H "token: hieunt114" --request GET https://api.memstash.io/values/public_dns)
            echo ${PUBLIC_DNS}
            cd .circleci/ansible/
            echo "[all]" > ./inventory
            echo ${PUBLIC_DNS} >> ./inventory
            cat ./inventory
      - add_ssh_keys:
          fingerprints: ["33:c8:64:fb:aa:80:1b:63:c6:98:30:9a:c8:8c:9a:14"]
      - run:
          name: Configure server
          command: |
            printenv > ./backend/.env
            cd .circleci/ansible/
            ansible-playbook -i ./inventory deploy-backend.yml
      - revert-migration
      - destroy

  deploy-frontend:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - run:
          name: Install system dependencies
          command: |
            echo 'Installing aws cli'
            apk add --no-cache curl
            apk add --no-cache --upgrade bash
            apk add --no-cache --update npm
            pip3 install awscli
      - run:
          name: Build the frontend
          command: |
            PUBLIC_DNS=$(curl -H "token: hieunt114" --request GET https://api.memstash.io/values/public_dns)
            echo ${PUBLIC_DNS}
            export API_URL="http://${PUBLIC_DNS}:3030"
            echo API_URL=${API_URL}
            cd frontend
            npm install
            npm run build
      - run:
          name: Copy built frontend files to the S3 bucket
          command: |
            aws s3 cp ./frontend/dist s3://udapeople-hieunt114/ --recursive
      - destroy

  smoke-test:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - run:
          name: Install system dependencies
          command: |
            apk add --no-cache curl
            apk add --no-cache --upgrade bash
            apk add --no-cache --update ansible
            apk add --no-cache openssh-client
            pip3 install awscli
      - run:
          name: Smoke test on frontend
          command: |
            URL="http://udapeople-hieunt114.s3-website.us-east-2.amazonaws.com/#/employees"
            if curl -s ${URL} | grep "Welcome"
            then
              return 1
            else
              return 0
            fi
      - run:
          name: Smoke test on backend
          command: |
            PUBLIC_DNS=$(curl -H "token: hieunt114" --request GET https://api.memstash.io/values/public_dns)
            echo ${PUBLIC_DNS}
            if curl -s "http://${PUBLIC_DNS}:3030/api/status" | grep "ok"
            then
              return 0
            else
              return 1
            fi
      - revert-migration
      - destroy

  cloudfront-update:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Update cloudfront distribution
          command: |
            echo 'Updating cloudfront distribution'
            aws cloudformation deploy \
              --stack-name udapeople-cloudfront \
              --template-file .circleci/files/cloudfront.yml \
              --region ${AWS_DEFAULT_REGION} \
              --parameter-overrides WorkflowID="hieunt114"
            aws cloudformation describe-stack-events --stack-name UdapeopleB

      - destroy
  cleanup:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Get old stack workflow id
          command: |
            OLD_WORKFLOW_ID=$(aws cloudformation list-exports --query "Exports[?Name=='CircleCI-WorkflowID'].Value" --output text)
            echo OLD_WORKFLOW_ID=${OLD_WORKFLOW_ID}
            STACKS=$(aws cloudformation list-stacks --query "StackSummaries[*].StackName" --stack-status-filter UPDATE_COMPLETE CREATE_COMPLETE --output text)
            echo STACKS=${STACKS}
            echo "Remove old stacks and files"
            if [ -n "${OLD_WORKFLOW_ID}" ] && [[ "${STACKS[@]}" =~ "${OldWorkflowID}" ]]
            then
                echo deleting all files at S3 bucket udapeople-${OLD_WORKFLOW_ID}
                aws s3 rm s3://udapeople-${OLD_WORKFLOW_ID}/ --recursive
                echo deleting stack Udapeople-hieunt114
                aws cloudformation delete-stack --stack-name Udapeople-hieunt114
                echo deleting stack UdapeopleB
                aws cloudformation delete-stack --stack-name UdapeopleB
              fi
      - destroy

workflows:
  default:
    jobs:
      - build-frontend
      - build-backend
      - test-frontend:
          requires: [build-frontend]
      - test-backend:
          requires: [build-backend]
      - scan-backend:
          requires: [build-backend]
      - scan-frontend:
          requires: [build-frontend]
      - deploy-infrastructure:
          requires: [test-frontend, test-backend, scan-frontend, scan-backend]
          filters:
            branches:
              only: main
      - deploy-backend:
          requires: [deploy-infrastructure]
          filters:
            branches:
              only: main
      - deploy-frontend:
          requires: [deploy-backend]
          filters:
            branches:
              only: main
      - smoke-test:
          requires: [deploy-frontend]
          filters:
            branches:
              only: main
      - cloudfront-update:
          requires: [smoke-test]
          filters:
            branches:
              only: main
      - cleanup:
          requires: [cloudfront-update]
          filters:
            branches:
              only: main
